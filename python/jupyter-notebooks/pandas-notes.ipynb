{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some quick notes for data munging using Pandas, Python, and Katt.\n",
    "\n",
    "Note: Jupyter notebook probably wasn't necessary for this, but it's good practice to get used to the keyboard shortcuts again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A review of Lambda\n",
    "\n",
    "To get through data munging faster, ```lambda``` functions define a function in a single line of code.  Some functions need more room, but as a rule of thumb, if it looks like something you could do in Excel, use a lambda.  The code is much easier to read.\n",
    "\n",
    "Below is an example of basic Lambda syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "mylambda = lambda x: (x * 2) + 3\n",
    "print(mylambda(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdas can also work through basic ```if``` gates.  (For the love of documentation, don't make this too complicated without expanding it into a larger function.)\n",
    "\n",
    "The following two code segments work the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n"
     ]
    }
   ],
   "source": [
    "def myfunction(x):\n",
    "    if x > 40:\n",
    "        return 40 + (x - 40) * 1.50\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "print(myfunction(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n"
     ]
    }
   ],
   "source": [
    "myfunction = lambda x: 40 + (x - 40) * 1.50 \\\n",
    "    if x > 40 else x\n",
    "    # See that slash above?  Use it when the lambda is more than one line.\n",
    "\n",
    "print(myfunction(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool.  For reference, here's a list of some of the most common data munging tasks.\n",
    "\n",
    "```python\n",
    "# Split a name in half and take the last name.\n",
    "get_last_name = lambda x: x.split(' ')[-1]\n",
    "df['last_name'] = df.name.apply(get_last_name)\n",
    "\n",
    "# Find an email provider, or anything else.  Note the different syntax:\n",
    "df['Email Provider'] = df.Email.apply(lambda x: x.split('@')[-1])\n",
    "\n",
    "# Change names of columns in a dataframe\n",
    "df.columns = ['ID', 'Title', 'Category', 'Year Released', 'Rating']\n",
    "\n",
    "# Rename columns of data -- better because of specificity\n",
    "df.rename(columns={\n",
    "  'id': 'ID',\n",
    "  'name': 'movie_title'},\n",
    "  inplace=True\n",
    ")\n",
    "\n",
    "# Using a lambda on a row, because more than one column value is needed behind an if statement\n",
    "total_earned = lambda row: (row.hourly_wage * 40) + ((row.hourly_wage * 1.5) * (row.hours_worked - 40)) \\\n",
    "    if row.hours_worked > 40 \\\n",
    "    else row.hourly_wage * row.hours_worked\n",
    "df['total_earned'] = df.apply(total_earned, axis = 1)\n",
    "\n",
    "# Make a new row that finds whether another row is NULL\n",
    "ad_clicks['is_click'] = ad_clicks.ad_click_timestamp.isnull()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well, here's some common aggregation functions to use on dataframe columns:\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    " mean | Average of all values in column |\n",
    "std | Standard deviation\n",
    "median | Median\n",
    "max | Maximum value in column\n",
    "min | Minimum value in column\n",
    "count | Number of values in column\n",
    "nunique | Number of unique values in column\n",
    "unique | List of unique values in column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If slicing and dicing is needed, aggregate by sub-type using syntax like:\n",
    "```df.groupby('column1').column2.measurement()```\n",
    "\n",
    "To make the output a proper dataframe instead of a series, add an ```reset_index()``` to the end, with both sets of parenthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can definitely start getting more complex, for example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "orders = pd.read_csv('orders.csv')\n",
    "cheap_shoes = orders.groupby('shoe_color').price.apply(lambda x: np.percentile(x, 25)).reset_index()\n",
    "```\n",
    "\n",
    "The above finds what the 25th percentile is for the uploaded dataframe of shoes, grouping by the shoe color, then assigning the result to a dataframe named ```cheap_shoes```.\n",
    "\n",
    "However, the above output is a tibble, which is hated by managers and UI folk everywhere.  Pandas thankfully can make a pivot table:\n",
    "\n",
    "```python\n",
    "shoe_counts_pivot = shoe_counts.pivot(\n",
    "\tcolumns='shoe_color',\n",
    "\tindex='shoe_type',\n",
    "\tvalues='id').reset_index()\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For merging, instead of using VLOOKUP a couple thousand times, you can use ```pd.merge(df1, df2)```.  The basic use of merge will merge together two dataframes using a column by the same name in each dataframe.  *Note: this is an Inner Join ONLY unless using ```how```*\n",
    "\n",
    "If the dataframes don't have a column named the same to link them together, the easiest way to deal with it is by using ```df1.rename()``` (see above), as the dictionary-based process can be sturdier and easier to troubleshoot.\n",
    "\n",
    "The process can be made even more explicit with the following:\n",
    "\n",
    "```python\n",
    "pd.merge(\n",
    "    orders,\n",
    "    customers,\n",
    "    left_on='customer_id',\n",
    "    right_on='id',\n",
    "    suffixes=['_order', '_customer'])\n",
    "    how='outer'\n",
    "```\n",
    "\n",
    "- ```left_on``` and ```right_on``` are the two columns the datasets are spliced together, or how to distinguish your foreign keys.  \n",
    "- ```suffixes``` are for when two columns in each df have the same column name.  By default, the one on the left will be \"x\" and on the right will be \"y\".\n",
    "- ```how``` is for the join type, and can be 'outer', 'left', or 'right' -- this defaults to inner, so be careful to not drop things\n",
    "- When playing with dataframes, use nice spacing.  It's a lot easier to work through nice spacing, and more logical to use spacing similar to SQL.  That way when a DBA gets pissed off, they won't also start swearing at your code, and everyone can read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge together two dataframes with identical columns (such as for data from two rounds of the same experiment, or two sign-up sheets), use ```pd.concat([df1, df2])```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
